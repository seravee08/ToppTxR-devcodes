{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run include.ipynb\n",
    "%run Net.ipynb\n",
    "%run Data.ipynb\n",
    "%run viewer.ipynb\n",
    "%run Medical_Utility.ipynb\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "class CNN(object):\n",
    "    \n",
    "    def __init__(self, general, arch):\n",
    "        \n",
    "        lr        = general[\"learning_rate\"]\n",
    "        beta1     = general[\"beta1\"]\n",
    "        beta2     = general[\"beta2\"]\n",
    "        loss_mode = general[\"loss\"]\n",
    "        reduction = general[\"reduction\"]\n",
    "        \n",
    "        cudnn.benchmark = FLAGS.cudnn_benchmark\n",
    "        gpu_num     = FLAGS.gpu_num\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available()\n",
    "                      and FLAGS.gpu_enable else \"cpu\")\n",
    "        torch.manual_seed(random.randint(1, 10000))\n",
    "        \n",
    "        self.input_dims1, layers1 = Net.parse_layers(arch[0])\n",
    "        #self.input_dims2, layers2 = Net.parse_layers(arch[1])\n",
    "        #self.net = Network_template_hook(gpu_num, layers1, layers2).to(self.device)\n",
    "        self.net = Network_template(gpu_num, layers1).to(self.device)\n",
    "        \n",
    "#         print(self.net.main[0].weight)\n",
    "#         print(\"=================================================================\")\n",
    "        \n",
    "#         from torchvision import models\n",
    "#         self.net = models.resnet50(pretrained=False).to(self.device)\n",
    "#         Net.init_weights(self.net, \"kaiming\")\n",
    "    \n",
    "#         print(self.net.main[0].weight)\n",
    "#         print(\"=================================================================\")\n",
    "        \n",
    "        self.criterion = StandardLoss(loss_mode, reduction).to(self.device)\n",
    "        #self.optimizer = optim.Adam(self.net.parameters(), lr=lr, betas=(beta1,beta2))\n",
    "        #self.optimizer = optim.SGD(self.net.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-2)\n",
    "        self.optimizer = optim.SGD(self.net.parameters(), lr=0.001)\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer)\n",
    "        \n",
    "    def optimize_step(self, Dtrain, labels):\n",
    "        #self.net.zero_grad()\n",
    "        self.optimizer.zero_grad()\n",
    "        loss = self.criterion([self.net, Dtrain, labels])\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "    \n",
    "    def gradual_outer_product(self, vec, interval):\n",
    "        num = int(np.ceil(len(vec)/interval))\n",
    "        res = [None] * num\n",
    "        start = 0\n",
    "        end = min(len(vec), interval)\n",
    "        for i in range(num):\n",
    "            outer_partial = np.outer(vec[start:end], vec)\n",
    "            res[i] = outer_partial.dot(vec)\n",
    "            start = start + interval\n",
    "            end = min(len(vec), start+interval)\n",
    "        res = np.concatenate(res, axis=0)\n",
    "        return res\n",
    "\n",
    "    def sparse_attention_batch_NCWHD(self, data):\n",
    "        batch_size = data.shape[0]\n",
    "        res = [None] * batch_size\n",
    "        for idx in range(batch_size):\n",
    "            item = np.squeeze(data[idx])\n",
    "            num_nonzero = np.prod(item.shape) - np.sum(item == np.amin(item))\n",
    "            print(num_nonzero)\n",
    "            print(num_nonzero/np.prod(item.shape))\n",
    "            shifted_item = item - np.amin(item)\n",
    "            nonz_dim0, nonz_dim1, nonz_dim2 = np.nonzero(shifted_item)\n",
    "            assert(num_nonzero == len(nonz_dim0))\n",
    "            flatten_ = np.zeros(num_nonzero)\n",
    "\n",
    "            for i in range(num_nonzero):\n",
    "                flatten_[i] = item[nonz_dim0[i]][nonz_dim1[i]][nonz_dim2[i]]\n",
    "            outer = self.gradual_outer_product(flatten_, 5000)\n",
    "            item_res = np.ones(item.shape) * np.amin(item)\n",
    "            for i in range(num_nonzero):\n",
    "                item_res[nonz_dim0[i]][nonz_dim1[i]][nonz_dim2[i]] = outer[i]\n",
    "            item_res = np.expand_dims(item_res, axis=0)\n",
    "            res[idx] = item_res\n",
    "        res = np.concatenate(res, axis=0)\n",
    "        res = np.expand_dims(res, axis=1)\n",
    "        return res\n",
    "        \n",
    "    def train(self, data_params, branch_name=\"Undefined Here\"):\n",
    "        \n",
    "        epochs           = data_params[\"epochs\"]\n",
    "        batch_size       = data_params[\"batch_size\"]\n",
    "        batch_workers    = data_params[\"batch_workers\"]\n",
    "        shuffle          = data_params[\"shuffle\"]\n",
    "        drop_last        = data_params[\"drop_last\"]\n",
    "        datasplit_scheme = data_params[\"datasplit_scheme\"]\n",
    "        test_split       = data_params[\"test_split\"]\n",
    "        xfold            = data_params[\"xfold\"]\n",
    "        fold_idx         = data_params[\"fold_idx\"]\n",
    "        random_seed      = data_params[\"random_seed\"]\n",
    "        train_loader = Data_fetcher.fetch_dataset(FLAGS.dataset, FLAGS.data_path, batch_size, batch_workers, shuffle, drop_last, 0.5, test_split, random_seed)\n",
    "        #train_loader, test_loader = Data_fetcher.fetch_dataset(FLAGS.dataset, FLAGS.data_path, batch_size, batch_workers, shuffle, drop_last, 0.5, test_split, random_seed)\n",
    "        #train_loader, test_loader = Data_fetcher.fetch_dataset_wValidation(FLAGS.dataset, FLAGS.data_path, batch_size, batch_workers, shuffle, drop_last, 0.5, datasplit_scheme, test_split, xfold, fold_idx, random_seed)\n",
    "        log           = open(FLAGS.log_path, \"a\")\n",
    "        log.write('Branch: %s  Fold ID: %d\\n\\n' % (branch_name, fold_idx))\n",
    "        log.flush()\n",
    "        \n",
    "        step = 0\n",
    "        if FLAGS.continue_model:\n",
    "            self.net.load_state_dict(torch.load('%s/net_step_%d.pth' % (FLAGS.model_save, FLAGS.model_step)))\n",
    "            step = FLAGS.model_step + 1\n",
    "            \n",
    "        lrec = []\n",
    "        best_f1 = -1.0\n",
    "        best_step = 0\n",
    "        stablize_step = 1000\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            for i, data in enumerate(train_loader, 0):\n",
    "                vol = data['img'].to(self.device)\n",
    "                labels = data['label'].to(self.device)\n",
    "              \n",
    "                if labels.shape[0] == 1:\n",
    "                    continue\n",
    "                loss_ = self.optimize_step(vol, labels)\n",
    "                lrec.append(loss_)\n",
    "                epoch_loss = epoch_loss + loss_\n",
    "                step = step + 1\n",
    "                \n",
    "                if step % FLAGS.print_step == 0:\n",
    "                    msg = ('[%d/%d][%d/%d] loss: %.4f Step: %d'\n",
    "                      %(epoch, epochs, i, len(train_loader), np.mean(np.asarray(lrec)), step))\n",
    "                    lrec[:] = []\n",
    "                    print(msg)\n",
    "                    log.write(msg+\"\\n\")\n",
    "                    log.flush()\n",
    "                    \n",
    "#                     label_pred_cum = np.array((),dtype=np.int32)\n",
    "#                     label_test_cum = np.array((),dtype=np.int32)\n",
    "#                     for j, data_test in enumerate(test_loader, 0):\n",
    "#                         vol_test   = data_test['vol'].unsqueeze(1).to(self.device)\n",
    "#                         label_test = data_test['label']\n",
    "#                         if label_test.shape[0] == 1:\n",
    "#                             continue\n",
    "#                         pred_test  = self.net(vol_test)\n",
    "#                         predicted  = torch.max(pred_test.data, 1)[1]\n",
    "#                         label_pred_cum = np.concatenate((label_pred_cum, predicted.detach().cpu()))\n",
    "#                         label_test_cum = np.concatenate((label_test_cum, label_test))\n",
    "\n",
    "#                     accuracy = Utility_MEDICAL.compute_accuracy(label_test_cum,label_pred_cum)\n",
    "#                     balanced_accuracy = Utility_MEDICAL.binary_balanced_evaluation(label_test_cum,label_pred_cum)\n",
    "#                     specificity, sensitivity = Utility_MEDICAL.compute_specificity_sensitivity(label_test_cum,label_pred_cum)\n",
    "#                     f1_score = Utility_MEDICAL.compute_F1(label_test_cum, label_pred_cum)\n",
    "#                     auc = roc_auc_score(label_test_cum, label_pred_cum)\n",
    "                    \n",
    "#                     if step > stablize_step:\n",
    "#                         if f1_score > best_f1:\n",
    "#                             best_f1 = f1_score\n",
    "#                             best_step = step\n",
    "                    \n",
    "#                     msg0 = ('Test accurady: %.4f  Balanced_accuracy: %.4f'%(accuracy, balanced_accuracy))\n",
    "#                     msg1 = ('Specificity: %.4f  Sensitivity: %.4f'%(specificity, sensitivity))\n",
    "#                     msg2 = ('AUC: %.4f\\nF1 score: %.4f'%(auc, f1_score))\n",
    "#                     msg3 = ('Best F1 score: %.4f  Step: %d' %(best_f1, best_step))\n",
    "#                     print(msg0)\n",
    "#                     print(msg1)\n",
    "#                     print(msg2)\n",
    "#                     print(msg3)\n",
    "#                     log.write(msg0+\"\\n\")\n",
    "#                     log.write(msg1+\"\\n\")\n",
    "#                     log.write(msg2+\"\\n\")\n",
    "#                     log.write(msg3+\"\\n\")\n",
    "#                     log.flush()\n",
    "                        \n",
    "                if step % FLAGS.save_step == 0:\n",
    "                    # ===== Save models ====\n",
    "                    torch.save(self.net.state_dict(), '%s/net_step_%d.pth' % (FLAGS.model_save, step))\n",
    "            self.scheduler.step(epoch_loss)\n",
    "        log.close()\n",
    "        print(\"Training complete.\")\n",
    "        \n",
    "    def test(self, data_params):\n",
    "        \n",
    "        epochs        = data_params[\"epochs\"]\n",
    "        batch_size    = data_params[\"batch_size\"]\n",
    "        batch_workers = data_params[\"batch_workers\"]\n",
    "        shuffle       = data_params[\"shuffle\"]\n",
    "        drop_last     = data_params[\"drop_last\"]\n",
    "        test_split    = data_params[\"test_split\"]\n",
    "        random_seed   = data_params[\"random_seed\"]\n",
    "        train_loader = Data_fetcher.fetch_dataset(FLAGS.dataset, FLAGS.data_path,  batch_size, batch_workers, shuffle, drop_last, 0.5, test_split, random_seed)\n",
    "        #train_loader, test_loader = Data_fetcher.fetch_dataset(FLAGS.dataset, FLAGS.data_path,  batch_size, batch_workers, shuffle, drop_last, 0.5, test_split, random_seed)\n",
    "        log           = open(FLAGS.log_path, \"a\")\n",
    "        \n",
    "        step = 0\n",
    "        if FLAGS.continue_model:\n",
    "            self.net.load_state_dict(torch.load('%s/net_step_%d.pth' % (FLAGS.model_save, FLAGS.model_step)))\n",
    "            step = FLAGS.model_step + 1\n",
    "            \n",
    "\n",
    "#         from torchvision import models\n",
    "#         model = models.resnet50(pretrained=True)\n",
    "#         model = models.vgg16(pretrained=True)\n",
    "#         model = model.features[:-2]\n",
    "#         model = models.densenet161(pretrained=False)\n",
    "#         target_layer = model.features.denseblock4.denselayer24\n",
    "#         target_layer = model.layer4\n",
    "#         target_layer = model[-1]\n",
    "#         model = self.net.main\n",
    "#         #print(model)\n",
    "#         #target_layer = self.net.layer4[-1].conv3\n",
    "#         target_layer = self.net.main[-11]\n",
    "#         rgb_img = cv2.imread(\"E:/Data2/Dog_Cat/train_subset2/cat.33.jpg\", 1)[:,:,::-1]\n",
    "#         rgb_img = cv2.resize(rgb_img, (256, 256))\n",
    "#         gradcam_guidedbackprop_visualize_single_image(rgb_img, model, target_layer, self.device)\n",
    "\n",
    "\n",
    "        model = VGG16(n_classes=2)\n",
    "        model.load_state_dict(torch.load('E:/Data2/Pytorch_Log/vgg16/cnn.pkl'))\n",
    "        target_layer = model.layer5\n",
    "\n",
    "        #rgb_img = np.float32(cv2.imread(\"E:/Data2/Dog_Cat/train_subset2/dog.248.jpg\", 1))/255\n",
    "        rgb_img = cv2.imread(\"E:/Data2/Dog_Cat/train_subset2/cat.133.jpg\", 1)[:,:,::-1]\n",
    "        rgb_img = cv2.resize(rgb_img, (224, 224))\n",
    "        gradcam_guidedbackprop_visualize_single_image(rgb_img, model, target_layer, self.device)\n",
    "    \n",
    "    \n",
    "    \n",
    "#         correct = 0\n",
    "#         total   = 0\n",
    "#         self.net.eval()\n",
    "#         for i, data in enumerate(train_loader, 0):\n",
    "#             vol = data['img'].to(self.device)\n",
    "#             labels = data['label'].numpy()\n",
    "#             out = self.net(vol)\n",
    "#             out = np.argmax(out.detach().cpu().numpy(), axis=1)\n",
    "#             total = total + out.shape[0]\n",
    "#             correct = correct + np.sum(out == labels)\n",
    "# #             target_layer = self.net.main[-7]\n",
    "# #             gradcam_guidedbackprop_visualize(vol[0,:], self.net.main, target_layer, self.device)\n",
    "# #             break\n",
    "#         print(correct * 1.0 / total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
